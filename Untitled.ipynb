{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "chance of student finishing the MOOC\n",
    "Training data: Climate\n",
    "Testing data: China\n",
    "SKLearn Preprocessing Normalize: Avg_Dt\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pydotplus \n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "PERSON_COURSE_CLEANED = \"../UBCx__Climate101x__3T2015_cleaned/person_course_cleaned.tsv\"\n",
    "PERSON_COURSE_DAY_CLEANED = \"../UBCx__Climate101x__3T2015_cleaned/person_course_day_cleaned.tsv\"\n",
    "PERSON_COURSE_CLEANED_CHINA = \"../UBCx__China300_1x__3T2015_cleaned/person_course_cleaned.tsv\"\n",
    "PERSON_COURSE_DAY_CLEANED_CHINA = \"../UBCx__China300_1x__3T2015_cleaned/person_course_day_cleaned.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(data_path1, data_path2, filename):\n",
    "    topdir = os.getcwd()\n",
    "    person_course_cleaned_path = os.path.join(topdir, data_path1)\n",
    "    person_course_day_cleaned_path = os.path.join(topdir, data_path2)\n",
    "\n",
    "    person_course_cleaned_df = pd.read_table(person_course_cleaned_path)\n",
    "    person_course_day_cleaned_df = pd.read_table(person_course_day_cleaned_path)\n",
    "\n",
    "    result_1 = pd.merge(person_course_cleaned_df, person_course_day_cleaned_df, on='user_id', how = 'inner')\n",
    "    def get_grade_label(grade):\n",
    "        '''\n",
    "        Return 1 if course was completed (non-NA value), 0 otherwise.\n",
    "        '''\n",
    "        if (pd.notnull(grade)):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    result_1['grade'] = result_1['grade'].map(get_grade_label)\n",
    "\n",
    "    '''\n",
    "    Dropping all the non-numerical values (for now)\n",
    "    '''\n",
    "    result = result_1.apply(pd.to_numeric, errors='coerce')\n",
    "    '''\n",
    "    Save all the categorical columns\n",
    "    '''\n",
    "    categorical_columns = result.columns[pd.isnull(result).all()].tolist()\n",
    "    result = result.dropna(axis=1, how='all')\n",
    "\n",
    "    '''\n",
    "    For the numerical values, replace all the NA's with 0's\n",
    "    (because if we only keep the rows that don't have NAs we only get 5 datapoints :'()\n",
    "    '''\n",
    "    result = result.fillna(0)\n",
    "    # result.to_csv('left-join.tsv', sep=\"\\t\")\n",
    "\n",
    "    '''\n",
    "    Since we don't want to normalize the grades, and want to use it as the labels instead, we store them separately\n",
    "    '''\n",
    "    grades = result['grade']\n",
    "    result = result.drop(['grade', 'user_id'], axis=1)\n",
    "\n",
    "    '''\n",
    "    Normalize the remaining numerical data: set it to have mean of 0 and standard deviation of 1.\n",
    "    '''\n",
    "    result_norm = result.apply(lambda x: (x - np.mean(x)) / np.std(x))\n",
    "    # result_norm.to_csv('result-norm.tsv', sep=\"\\t\")\n",
    "\n",
    "    '''\n",
    "    Now convert the categorical features into binary features\n",
    "    '''\n",
    "    cat_data = result_1[categorical_columns]\n",
    "    cat_data.applymap(str)\n",
    "    cat_data.fillna(\"\")\n",
    "\n",
    "\n",
    "    cat_data = pd.get_dummies(cat_data.drop(['continent','start_time','last_event_x','last_event_y','date'], axis=1))\n",
    "    final_frame = cat_data.join(result)\n",
    "    return [final_frame, grades]\n",
    "    \n",
    "    \n",
    "\n",
    "set0 = get_data(PERSON_COURSE_CLEANED, PERSON_COURSE_DAY_CLEANED, 'final-result.tsv')\n",
    "set1 = get_data(PERSON_COURSE_CLEANED_CHINA, PERSON_COURSE_DAY_CLEANED_CHINA, 'final-result-china.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_path1, data_path2, filename = PERSON_COURSE_CLEANED, PERSON_COURSE_DAY_CLEANED, 'final-result.tsv'\n",
    "topdir = os.getcwd()\n",
    "person_course_cleaned_path = os.path.join(topdir, data_path1)\n",
    "person_course_day_cleaned_path = os.path.join(topdir, data_path2)\n",
    "\n",
    "person_course_cleaned_df = pd.read_table(person_course_cleaned_path)\n",
    "person_course_day_cleaned_df = pd.read_table(person_course_day_cleaned_path)\n",
    "\n",
    "result_1 = pd.merge(person_course_cleaned_df, person_course_day_cleaned_df, on='user_id', how = 'inner')\n",
    "def get_grade_label(grade):\n",
    "    '''\n",
    "    Return 1 if course was completed (non-NA value), 0 otherwise.\n",
    "    '''\n",
    "    if (pd.notnull(grade)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "result_1['grade'] = result_1['grade'].map(get_grade_label)\n",
    "\n",
    "'''\n",
    "Dropping all the non-numerical values (for now)\n",
    "'''\n",
    "result = result_1.apply(pd.to_numeric, errors='coerce')\n",
    "'''\n",
    "Save all the categorical columns\n",
    "'''\n",
    "categorical_columns = result.columns[pd.isnull(result).all()].tolist()\n",
    "result = result.dropna(axis=1, how='all')\n",
    "\n",
    "'''\n",
    "For the numerical values, replace all the NA's with 0's\n",
    "(because if we only keep the rows that don't have NAs we only get 5 datapoints :'()\n",
    "'''\n",
    "result = result.fillna(0)\n",
    "# result.to_csv('left-join.tsv', sep=\"\\t\")\n",
    "\n",
    "'''\n",
    "Since we don't want to normalize the grades, and want to use it as the labels instead, we store them separately\n",
    "'''\n",
    "grades = result['grade']\n",
    "result = result.drop(['grade', 'user_id'], axis=1)\n",
    "\n",
    "'''\n",
    "Normalize the remaining numerical data: set it to have mean of 0 and standard deviation of 1.\n",
    "'''\n",
    "result_norm = result.apply(lambda x: (x - np.mean(x)) / np.std(x))\n",
    "# result_norm.to_csv('result-norm.tsv', sep=\"\\t\")\n",
    "\n",
    "'''\n",
    "Now convert the categorical features into binary features\n",
    "'''\n",
    "cat_data = result_1[categorical_columns]\n",
    "cat_data.applymap(str)\n",
    "cat_data.fillna(\"\")\n",
    "\n",
    "\n",
    "cat_data = pd.get_dummies(cat_data.drop(['continent','start_time','last_event_x','last_event_y','date'], axis=1))\n",
    "final_frame = cat_data.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=5)\n",
    "clf = clf.fit(set0[0],set0[1])\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,feature_names=list(set0[0]),  \n",
    "                         class_names=['Pass','Fail'],  \n",
    "                         filled=True, rounded=True) \n",
    "graph = pydotplus.graph_from_dot_data(dot_data) \n",
    "graph.write_pdf(\"gradetree.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the climate course: \n",
      "Overall accuracy: 0.839343459089\n",
      "False positive rate: 0.104752572268\n",
      "For the China course: \n",
      "Overall accuracy: 0.846011987091\n",
      "False positive rate: 0.130843706777\n"
     ]
    }
   ],
   "source": [
    "def get_scores(clf, final_frame, grades):\n",
    "    scores = []\n",
    "    fps = []\n",
    "    fns = []\n",
    "    kf = KFold(n_splits=5)\n",
    "    for train_index, test_index in kf.split(final_frame):\n",
    "        X_train, X_test = final_frame.ix[train_index, :], final_frame.ix[test_index,:]\n",
    "        y_train, y_test = grades.ix[train_index], grades.ix[test_index]\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        scores.append(clf.score(X_test,y_test))\n",
    "        num_ones = np.mean((pred == 1) & (y_test != 1))\n",
    "        num_zeros = np.mean((pred == 0) & (y_test != 0))\n",
    "        fps.append(num_ones)\n",
    "        fns.append(num_zeros)\n",
    "    print(\"Overall accuracy: \" + str(np.mean(scores)))\n",
    "    print(\"False positive rate: \" + str(np.mean(fps)))\n",
    "    #print(np.mean(fns))\n",
    "\n",
    "print(\"For the climate course: \")\n",
    "get_scores(clf, set0[0], set0[1])\n",
    "print(\"For the China course: \")\n",
    "get_scores(clf, set1[0], set1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BarContainer' object has no attribute 'set_xticklabels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-69172433921f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m axes = plt.bar(range(len(final_frame.columns)), importances[indices],\n\u001b[1;32m     13\u001b[0m        color=\"r\", yerr=std[indices], align=\"center\")\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BarContainer' object has no attribute 'set_xticklabels'"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth = 5, n_estimators = 10)\n",
    "clf = clf.fit(final_frame, grades)\n",
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "figure, axes = plt.subplots(nrows = 1, ncols = 1)\n",
    "plt.title(\"Feature importances\")\n",
    "axes = plt.bar(range(len(final_frame.columns)), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "axes.set_xticklabels(final_frame.columns)\n",
    "plt.xlim([-1, len(final_frame.columns)])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
